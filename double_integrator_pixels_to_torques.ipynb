{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a state of the double integrator\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"double_integrator_brick.svg\" width=\"350\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initial state and parameters\n",
    "\n",
    "## parameters\n",
    "width  = 10.0 # width of brick in pixels\n",
    "height = 5.0\n",
    "t_f = 100     # number of time steps\n",
    "\n",
    "## state\n",
    "x    = 30.0 # position to right in pixels\n",
    "xdot = 0.0  # \n",
    "\n",
    "state_initial = torch.FloatTensor([x, xdot])\n",
    "state_initial = Variable(state_initial, requires_grad=False)\n",
    "print state_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiably render double integrator\n",
    "\n",
    "- Convert state of double integrator to an AABB list of corners in img\n",
    "- Find all pixels inside AABB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pi = np.pi\n",
    "\n",
    "def convert_world_to_img_coordinates(world_coordinates):\n",
    "    return world_coordinates + 50\n",
    "\n",
    "def torch_flip(two_element_tensor):\n",
    "    return torch.FloatTensor([two_element_tensor[1],two_element_tensor[0]])\n",
    "    \n",
    "def torch_det(A,B):\n",
    "    return A[0]*B[1] - A[1]*B[0]\n",
    "\n",
    "\n",
    "def distance_pytorch(A, B, P):\n",
    "    if (A == B).all() or (B == P).all():\n",
    "        return 0\n",
    "    if (torch.acos(torch.FloatTensor([torch.dot((P - A) / (P - A).norm(), \n",
    "                                                (B - A) / (B - A).norm())])) > pi/2).all():\n",
    "        return (P - A).norm()\n",
    "    \n",
    "    if (torch.acos(torch.FloatTensor([torch.dot((P - B) / (P - B).norm(), \n",
    "                                                (A - B) / (A - B).norm())])) > pi/2).all():\n",
    "        return (P - B).norm()\n",
    "    \n",
    "    return abs(torch_det(A-B, A-P))/(B-A).norm()\n",
    "\n",
    "\n",
    "## renderer\n",
    "def inside_aabb(aabb_corners, P):\n",
    "    # check x conditions\n",
    "    if (P[0] < aabb_corners[0][0]).all() or (P[0] > aabb_corners[3][0]).all():\n",
    "        return False\n",
    "    \n",
    "    # check y conditions\n",
    "    if (P[1] < aabb_corners[0][1]).all() or (P[1] > aabb_corners[3][1]).all():\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def distance_to_aabb(aabb_corners, P):\n",
    "    # if inside aabb, return 0\n",
    "    distance_to_left   = distance_pytorch(aabb_corners[0], aabb_corners[1], P)\n",
    "    distance_to_top    = distance_pytorch(aabb_corners[1], aabb_corners[3], P)\n",
    "    distance_to_right  = distance_pytorch(aabb_corners[0], aabb_corners[1], P)\n",
    "    distance_to_bottom = distance_pytorch(aabb_corners[0], aabb_corners[1], P) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def double_integrator_state_to_img(state):\n",
    "    center = Variable(torch.zeros(2), requires_grad = False)\n",
    "    center[1] = state[0]\n",
    "    center_in_img = convert_world_to_img_coordinates(center)\n",
    "\n",
    "    lower_left  = center + Variable(torch.FloatTensor([0,      -width/2]), requires_grad=False)\n",
    "    upper_left  = center + Variable(torch.FloatTensor([height, -width/2]), requires_grad=False)\n",
    "    lower_right = center + Variable(torch.FloatTensor([0,       width/2]), requires_grad=False)\n",
    "    upper_right = center + Variable(torch.FloatTensor([height,  width/2]), requires_grad=False)\n",
    "\n",
    "    corners = [lower_left, upper_left, lower_right, upper_right]\n",
    "    corners_in_img = [convert_world_to_img_coordinates(x) for x in corners]\n",
    "    \n",
    "    img = Variable(torch.zeros((100,100)), requires_grad=False)\n",
    "\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            this_img_coord = torch.FloatTensor([i,j])\n",
    "            if inside_aabb(corners_in_img, this_img_coord):\n",
    "                img[i,j] = 1.0\n",
    "            else:\n",
    "                img[i,j] = 0.0\n",
    "\n",
    "    return img\n",
    "\n",
    "img = double_integrator_state_to_img(state_initial)\n",
    "plt.imshow(img.data, cmap=plt.get_cmap('gray_r'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State feedback: perform state feedback with just PD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_origin_controller(state):\n",
    "    x_desired = 0\n",
    "    xdot_desired = 0\n",
    "    diff_pos = (x_desired    - state[0])\n",
    "    diff_vel = (xdot_desired - state[1])\n",
    "    u = 1000*diff_pos + 100*diff_vel\n",
    "    if (u > 500).all():\n",
    "        u = u*0 + 500  # this trick mantains u as a Variable\n",
    "    if (u < -500).all():\n",
    "        u = u*0 -500\n",
    "    return u\n",
    "\n",
    "def double_integrator_next_state(state, u):\n",
    "    deriv = Variable(torch.zeros(2), requires_grad = False)\n",
    "    deriv[0] = state[1]\n",
    "    deriv[1] = u\n",
    "    dt = .01\n",
    "    next_state = state + deriv*dt\n",
    "    return next_state\n",
    "\n",
    "state_tape = []\n",
    "state_tape.append(state_initial)\n",
    "\n",
    "for i in range(100):\n",
    "    u = pd_origin_controller(state_tape[-1])\n",
    "    next_state = double_integrator_next_state(state_tape[-1],u)\n",
    "    state_tape.append(next_state)\n",
    "    \n",
    "print len(state_tape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert states to imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tape = []\n",
    "\n",
    "for i in state_tape:\n",
    "    img_tape.append(double_integrator_state_to_img(i))\n",
    "    \n",
    "print len(img_tape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "def get_animation(img_tape):\n",
    "    fig = plt.figure()\n",
    "    first_img = img_tape[0].data\n",
    "    im = plt.imshow(first_img, cmap='gist_gray_r')\n",
    "\n",
    "    def init():\n",
    "        im.set_data(first_img)\n",
    "\n",
    "    def animate(i):\n",
    "        im.set_data(img_tape[i].data)\n",
    "        return im\n",
    "\n",
    "    animate = animation.FuncAnimation(fig, animate, init_func=init, frames=len(img_tape), interval=20, blit=True)\n",
    "    plt.close(fig)\n",
    "    return animate\n",
    "    \n",
    "ani = get_animation(img_tape)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting etc examples for reference\n",
    "# https://gist.github.com/AndrewWalker/2687988\n",
    "# https://matplotlib.org/examples/animation/double_pendulum_animated.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization over output feedback policies\n",
    "\n",
    "We would like to directly optimize an output feedback policy $\\pi$, i.e.\n",
    "\n",
    "\\begin{align*}\n",
    "        \\min_{x(.), u(.), \\pi} \\ \\ \\ & \\int_{t_0}^{t_f} g(x(t),u(t)) dt\\\\\n",
    "        s.t. \\ \\ \\  & \\forall t, \\ \\ \\dot{x}(t) = f(x(t),u(t)), \\\\\n",
    "        & x(t_0) = x_0, \\\\\n",
    "        & u = \\pi(y(x))\n",
    "\\end{align*}\n",
    "\n",
    "Where $y(x)$ is the renderer.\n",
    "\n",
    "We would like to solve this optimization from many initial samples $x_{0,i}$ and simultaneously optimize the feedback policy given a particular form, for example linear feedback $u = Ky(x)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconstrained \"shooting\" method optimization for linear feedback from one initial condition\n",
    "\n",
    "For one initial condition $x_0$, linear feedback $u = Ky(x)$, and one choice of time horizon $t_f$, we can formulate this is a shooting method type optimization as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "        \\min_{K} \\ \\ \\ & \\int_{t_0}^{t_f} g(x(t),u(t)) dt\\\\\n",
    "        s.t. \\ \\ \\  & \\forall t, \\ \\ \\dot{x}(t) = f(x(t),u(t)), \\\\\n",
    "        & x(t_0) = x_0, \\\\\n",
    "        & u = Ky(x)\n",
    "\\end{align*}\n",
    "\n",
    "With our decision variables being only K, we can solve this from an initial guess and backpropagation.  This could work for any differentiable feedback policy $\\pi$ but we can start with just linear feedback.\n",
    "\n",
    "We'll use the simplest quadratic cost:\n",
    "\n",
    "$$g(x(t), u(t)) = x^Tx + u^Tu $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### output feedback policy\n",
    "\n",
    "## initial policy parameters\n",
    "flat_img = img.view(-1,1)\n",
    "K = Variable(torch.rand(flat_img.shape), requires_grad=True)\n",
    "\n",
    "## policy\n",
    "def output_feedback_policy(flat_img, K):\n",
    "    return torch.t(K).mm(flat_img)\n",
    "\n",
    "state_tape = []\n",
    "state_tape.append(state_initial)\n",
    "img_tape = []\n",
    "img_tape.append(double_integrator_state_to_img(state_initial))\n",
    "u_tape = []\n",
    "    \n",
    "### simulate initial policy\n",
    "for i in range(t_f):\n",
    "    y = img_tape[-1]\n",
    "    flat_img = y.view(-1,1)\n",
    "    u = output_feedback_policy(flat_img, K)\n",
    "    next_state = double_integrator_next_state(state_tape[-1],u[0][0])\n",
    "    state_tape.append(next_state)\n",
    "    next_y     = double_integrator_state_to_img(next_state) \n",
    "    img_tape.append(next_y)\n",
    "    u_tape.append(u)\n",
    "    \n",
    "print len(state_tape)\n",
    "print len(img_tape)\n",
    "print len(u_tape)\n",
    "\n",
    "## after the fact, go get the running cost\n",
    "cost = 0\n",
    "for i in state_tape[1:]:\n",
    "    cost += i.pow(2).sum()\n",
    "    \n",
    "for i in u_tape:\n",
    "    cost += i.pow(2).sum()\n",
    "    \n",
    "print cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize initial policy\n",
    "\n",
    "ani = get_animation(img_tape)\n",
    "HTML(ani.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimize\n",
    "\n",
    "num_iterations = 100\n",
    "step_rate = 1e-6\n",
    "\n",
    "K = Variable(torch.randn(flat_img.shape), requires_grad=True)\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    print \"iter\", i\n",
    "    \n",
    "    state_tape = []\n",
    "    \n",
    "    state_tape.append(state_initial)\n",
    "    img_tape = []\n",
    "    img_tape.append(double_integrator_state_to_img(state_initial))\n",
    "    u_tape = []\n",
    "    \n",
    "    ### simulate policy\n",
    "    for i in range(t_f):\n",
    "        y = img_tape[-1]\n",
    "        flat_img = y.view(-1,1)\n",
    "        u = output_feedback_policy(flat_img, K)\n",
    "        next_state = double_integrator_next_state(state_tape[-1],u[0][0])\n",
    "        state_tape.append(next_state)\n",
    "        next_y     = double_integrator_state_to_img(next_state) \n",
    "        img_tape.append(next_y)\n",
    "        u_tape.append(u)\n",
    "\n",
    "\n",
    "    ## after the fact, go get the running cost\n",
    "    cost = 0\n",
    "    for i in state_tape[1:]:\n",
    "        cost += i.pow(2).sum()\n",
    "\n",
    "    for i in u_tape:\n",
    "        cost += i.pow(2).sum()\n",
    "        \n",
    "    ## Automatically differentiate\n",
    "    cost.backward()\n",
    "\n",
    "    # Update K via gradient descent\n",
    "    K.data -= step_rate * K.grad.data\n",
    "      \n",
    "    # Manually zero the gradients after running the backward pass\n",
    "    K.grad.data.zero_()\n",
    "    \n",
    "print K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize final policy\n",
    "\n",
    "ani = get_animation(img_tape)\n",
    "HTML(ani.to_html5_video())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
